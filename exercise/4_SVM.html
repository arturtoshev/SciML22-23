
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Support Vector Machines &#8212; Introduction to Scientific Machine Learning for Engineers</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Admin" href="../admin.html" />
    <link rel="prev" title="3. Optimization" href="3_optimization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Scientific Machine Learning for Engineers</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../about.html">
                    About this Lecture
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/preliminaries.html">
   Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/motivation.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/cc-1-linear.html">
   Core Content 1: Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/cc-2-optimization.html">
   Core Content 2: Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/cc-3-classic-ml.html">
   Core Content 3: Classic ML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture/cc-4-dl.html">
   Core Content 4: Deep Learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Exercise
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1_linReg_logReg.html">
   1. Linear Regression and Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_BayesianInference.html">
   2. Bayesian Linear and Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3_optimization.html">
   3. Optimization
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Support Vector Machines
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../admin.html">
   Admin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../books.html">
   Books
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminary_knowledge.html">
   Preliminary Knowledge
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq.html">
   Frequently Asked Questions
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://colab.research.google.com/github/arturtoshev/SciML22-23/blob/master/exercise/4_SVM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/arturtoshev/SciML22-23"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/arturtoshev/SciML22-23/issues/new?title=Issue%20on%20page%20%2Fexercise/4_SVM.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/exercise/4_SVM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#artificial-dataset">
   4.1 Artificial Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sequential-minimal-optimization-smo">
   4.2 Sequential Minimal Optimization (SMO)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent-optimization">
   4.3 Gradient Descent Optimization
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>4. Support Vector Machines</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#artificial-dataset">
   4.1 Artificial Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sequential-minimal-optimization-smo">
   4.2 Sequential Minimal Optimization (SMO)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent-optimization">
   4.3 Gradient Descent Optimization
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="support-vector-machines">
<h1>4. Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">#</a></h1>
<p>At the end of this exercise you will know:</p>
<ul class="simple">
<li><p>How to train a SVM using Sequential Minimal Optimization (SMO)</p></li>
<li><p>How to train a SVM using Gradient Descent (GD)</p></li>
<li><p>How different SVM Kernels perform</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span><span class="p">,</span> <span class="n">make_circles</span><span class="p">,</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Summary of the mathematical formalism</strong></p>
<p>Soft Margin SVM Lagrangian:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\omega, b, \xi, \alpha, \mu)=\frac{1}{2} \omega^{T} \omega+C \sum_{i=1}^{m} \xi_{i} -\sum_{i=1}^{m} \alpha_{i}\left[y^{(i)}\left(\omega^{\top} x^{(i)}+b\right)-1+\xi_{i}\right]-\sum_{i=1}^{m} \mu_{i} \xi_{i}.
\]</div>
<p>Primal problem:</p>
<div class="math notranslate nohighlight">
\[
\min _{\omega, b} \left( \frac{1}{2}\|\omega\|^{2}+C \sum_{i=1}^{m} \xi_{i}\right)
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\text{s.t.}\left\{\begin{array}{l}y^{(i)}\left(\omega^{\top} x^{(i)}+b\right) \geq 1-\xi_{i}, \quad i=1, \ldots, m \\ \xi_{i} \ge 0, \quad i=1, \ldots, \mathrm{m}\end{array}\right.
\end{split}\]</div>
<p>Dual problem:</p>
<div class="math notranslate nohighlight">
\[
\max_{\alpha} \left( \sum_{i=1}^{m} \alpha_{i}-\frac{1}{2} \sum_{i,j=1}^{m} y^{(i)} y^{(j)} \alpha_{i} \alpha_{j} K(x^{(i)}, x^{(j)}) \right)
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\text { s.t. }\left\{\begin{array}{l}
0 \leq \alpha_{i} \leq C, \quad i=1, \ldots, m \\
\sum_{i=1}^{m} \alpha_{i} y^{(i)}=0
\end{array}\right.
\end{split}\]</div>
<p>In the dual problem, we have used that <span class="math notranslate nohighlight">\(w=\sum_{i=1}^{m} \alpha_{i} y^{(i)} x^{(i)}\)</span> and <span class="math notranslate nohighlight">\(\sum_{i=1}^{m} \alpha_{i} y^{(i)}=0\)</span> to get rid of <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. To then find <span class="math notranslate nohighlight">\(b\)</span>, we use the heuristic <span class="math notranslate nohighlight">\(b^* = \frac{1}{m_{\Sigma}} \sum_{j=1}^{m_{\Sigma}}\left(y^{(j)}-\sum_{i=1}^{m_{\Sigma}} \alpha_{i}^{*} y^{(i)}K(x^{(i)}, x^{(j)})\right)\)</span> over the support vectors <span class="math notranslate nohighlight">\(m_{\Sigma}\)</span>. Note, only in the linear case, the kernel becomes <span class="math notranslate nohighlight">\(K(x^{(i)}, x^{(j)}) = \left\langle x^{(i)}, x^{(j)}\right\rangle\)</span>. Also note, that only in the dual problem definition we encounter the kernel and can use the kernel trick.</p>
<blockquote>
<div><p>Note: for <span class="math notranslate nohighlight">\(C \to \infty\)</span> this problem ends up being the Hard Margin SVM.</p>
</div></blockquote>
<section id="artificial-dataset">
<h2>4.1 Artificial Dataset<a class="headerlink" href="#artificial-dataset" title="Permalink to this headline">#</a></h2>
<p>We use scikit-learn and <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html"><code class="docutils literal notranslate"><span class="pre">make_blobs</span></code></a> to generate a binary dataset with input features <span class="math notranslate nohighlight">\(x\in \mathbb{R}^2\)</span> and labels <span class="math notranslate nohighlight">\(y\in \{-1, +1\}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X as features and Y as labels</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="c1"># by default the labels are {0, 1}, so we change them to {-1,1}</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># we also center the input data (per dimension) and scale it to unit variance to make trainig more efficient</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">/</span><span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x7fd8a05ab3d0&gt;
</pre></div>
</div>
<img alt="../_images/4_SVM_4_1.png" src="../_images/4_SVM_4_1.png" />
</div>
</div>
</section>
<section id="sequential-minimal-optimization-smo">
<h2>4.2 Sequential Minimal Optimization (SMO)<a class="headerlink" href="#sequential-minimal-optimization-smo" title="Permalink to this headline">#</a></h2>
<p>This algorithm was originally developed by <a class="reference external" href="http://research.microsoft.com/pubs/69644/tr-98-14.pdf">John Platt in 1998</a> and is optimized for SVM optimization. This algorithm solves the dual problem in a gradient-free manner. It selects two multiplier <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(\alpha_j\)</span> and optimizes them while keeping all other <span class="math notranslate nohighlight">\(\alpha\)</span>s constant. And then itertively repeats the procedure over all <span class="math notranslate nohighlight">\(\alpha\)</span>s. The efficiency lies in the heuristic used for selecting two <span class="math notranslate nohighlight">\(\alpha\)</span> values, which is based on information from previous iterations. In the end we obtain a vector of <span class="math notranslate nohighlight">\(M\)</span> values for <span class="math notranslate nohighlight">\(\alpha\)</span> corresponding to each training data point, for which most of the <span class="math notranslate nohighlight">\(\alpha\)</span> values are <span class="math notranslate nohighlight">\(0\)</span> and only the non-zero values contribute to the predictions made by the model.</p>
<p>We adapt the implementation of the SMO algorithm from <a class="reference external" href="https://jonchar.net/notebooks/SVM/">this</a> reference code by Jon Charest.</p>
<p><strong>Visualization Utils</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">levels</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Plots the model&#39;s decision boundary on the input axes object.</span>
<span class="sd">        Range of decision boundary grid is determined by the training data.</span>
<span class="sd">        Returns decision boundary grid and axes object (`grid`, `ax`).&quot;&quot;&quot;</span>

    <span class="c1"># Generate coordinate grid of shape [resolution x resolution]</span>
    <span class="c1"># and evaluate the model over the entire space</span>
    <span class="n">xrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">yrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                         <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">resolution</span><span class="p">)</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="p">[[</span><span class="n">decision_function</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
                               <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                               <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xr</span><span class="p">,</span> <span class="n">yr</span><span class="p">]),</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">xr</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">]</span> <span class="k">for</span> <span class="n">yr</span> <span class="ow">in</span> <span class="n">yrange</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xrange</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">yrange</span><span class="p">))</span>

    <span class="c1"># Plot decision contours using grid and</span>
    <span class="c1"># make a scatter plot of training data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xrange</span><span class="p">,</span> <span class="n">yrange</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">levels</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
               <span class="n">linestyles</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

    <span class="c1"># Plot support vectors (non-zero alphas)</span>
    <span class="c1"># as circled points (linewidth &gt; 0)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">0.0</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">grid</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<p>As a first step, we define a generic SMO model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SMOModel</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Container object for the model used for sequential minimal optimization.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">errors</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>               <span class="c1"># training data vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>               <span class="c1"># class label vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>               <span class="c1"># regularization parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>     <span class="c1"># kernel function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span>     <span class="c1"># lagrange multiplier vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>               <span class="c1"># scalar bias term</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>     <span class="c1"># error cache used for selection of alphas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obj</span> <span class="o">=</span> <span class="p">[]</span>           <span class="c1"># record of objective function value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>     <span class="c1"># store size of training set</span>
</pre></div>
</div>
</div>
</div>
<p>The next thing we need to define is the kernel. We start with the simplest linear kernel</p>
<div class="math notranslate nohighlight">
\[K(x,x') = x^{\top} x' + b.\]</div>
<p>The implementation of the radial basis function</p>
<div class="math notranslate nohighlight">
\[K(x,x') = \exp \left\{ - \gamma ||x-x'||_2^2 \right\} \]</div>
<p>we leave as an exercise for you.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linear_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the linear combination of arrays `x` and `y` with</span>
<span class="sd">    the optional bias term `b` (set to 1 by default).&quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">x</span> <span class="o">@</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># Note the @ operator for matrix multiplication</span>

<span class="k">def</span> <span class="nf">gaussian_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the gaussian similarity of arrays `x` and `y` with</span>
<span class="sd">    kernel inverse width parameter `gamma` (set to 1 by default).&quot;&quot;&quot;</span>
    
    <span class="c1">######################</span>
    <span class="c1"># TODO:</span>
    
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="c1">#######################</span>
</pre></div>
</div>
</div>
</div>
<p>Now, using the dual problem formulation and a <code class="docutils literal notranslate"><span class="pre">kernel</span></code>, we define the objective and decision functions.
The decision function simple imlements <span class="math notranslate nohighlight">\((\omega x + b)\)</span> by using the kernel trick and the relation <span class="math notranslate nohighlight">\(w=\sum_{i=1}^{m} \alpha_{i} y^{(i)} x^{(i)}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Objective function to optimize, i.e. loss function</span>

<span class="k">def</span> <span class="nf">objective_function</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">X_train</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the SVM objective function based in the input model defined by:</span>
<span class="sd">    `alphas`: vector of Lagrange multipliers</span>
<span class="sd">    `target`: vector of class labels (-1 or 1) for training data</span>
<span class="sd">    `kernel`: kernel function</span>
<span class="sd">    `X_train`: training data for model.&quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">target</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">target</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">alphas</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">alphas</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]))</span>


<span class="c1"># Decision function, i.e. forward model evaluation</span>

<span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies the SVM decision function to the input feature vectors in `x_test`.&quot;&quot;&quot;</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">alphas</span> <span class="o">*</span> <span class="n">target</span><span class="p">)</span> <span class="o">@</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
</div>
<p><strong>The SMO algorithm</strong></p>
<p>We are now ready to implement the SMO algorithm as given in Platt’s paper. The implementation is split into three functions: <code class="docutils literal notranslate"><span class="pre">take_step</span></code>, <code class="docutils literal notranslate"><span class="pre">examine_example</span></code>, and <code class="docutils literal notranslate"><span class="pre">train</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train</span></code> is the main training loop and also implements the selection of the first of the two <span class="math notranslate nohighlight">\(\alpha\)</span> values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">examine_example</span></code> implements the selection of the second <span class="math notranslate nohighlight">\(\alpha\)</span> value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">take_step</span></code> optimizes the two <span class="math notranslate nohighlight">\(\alpha\)</span> values, the bias <span class="math notranslate nohighlight">\(b\)</span>, and the cache.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">take_step</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

    <span class="c1"># Skip if chosen alphas are the same</span>
    <span class="k">if</span> <span class="n">i1</span> <span class="o">==</span> <span class="n">i2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="n">model</span>

    <span class="n">alph1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i1</span><span class="p">]</span>
    <span class="n">alph2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i1</span><span class="p">]</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">E1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">i1</span><span class="p">]</span>
    <span class="n">E2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">*</span> <span class="n">y2</span>

    <span class="c1"># Compute L &amp; H, the bounds on new possible alpha values</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">y1</span> <span class="o">!=</span> <span class="n">y2</span><span class="p">):</span>
        <span class="n">L</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">alph2</span> <span class="o">-</span> <span class="n">alph1</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span> <span class="o">+</span> <span class="n">alph2</span> <span class="o">-</span> <span class="n">alph1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">y1</span> <span class="o">==</span> <span class="n">y2</span><span class="p">):</span>
        <span class="n">L</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">alph1</span> <span class="o">+</span> <span class="n">alph2</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">alph1</span> <span class="o">+</span> <span class="n">alph2</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">L</span> <span class="o">==</span> <span class="n">H</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="n">model</span>

    <span class="c1"># Compute kernel &amp; 2nd derivative eta</span>
    <span class="n">k11</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i1</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i1</span><span class="p">])</span>
    <span class="n">k12</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i1</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i2</span><span class="p">])</span>
    <span class="n">k22</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i2</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i2</span><span class="p">])</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k12</span> <span class="o">-</span> <span class="n">k11</span> <span class="o">-</span> <span class="n">k22</span>

    <span class="c1"># Compute new alpha 2 (a2) if eta is negative</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">eta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">alph2</span> <span class="o">-</span> <span class="n">y2</span> <span class="o">*</span> <span class="p">(</span><span class="n">E1</span> <span class="o">-</span> <span class="n">E2</span><span class="p">)</span> <span class="o">/</span> <span class="n">eta</span>
        <span class="c1"># Clip a2 based on bounds L &amp; H</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">&lt;</span> <span class="n">a2</span> <span class="o">&lt;</span> <span class="n">H</span><span class="p">:</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">a2</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">a2</span> <span class="o">&lt;=</span> <span class="n">L</span><span class="p">):</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">L</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">a2</span> <span class="o">&gt;=</span> <span class="n">H</span><span class="p">):</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">H</span>

    <span class="c1"># If eta is non-negative, move new a2 to bound with greater objective function value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alphas_adj</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">alphas_adj</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span>
        <span class="c1"># objective function output with a2 = L</span>
        <span class="n">Lobj</span> <span class="o">=</span> <span class="n">objective_function</span><span class="p">(</span><span class="n">alphas_adj</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="n">alphas_adj</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">H</span>
        <span class="c1"># objective function output with a2 = H</span>
        <span class="n">Hobj</span> <span class="o">=</span> <span class="n">objective_function</span><span class="p">(</span><span class="n">alphas_adj</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Lobj</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">Hobj</span> <span class="o">+</span> <span class="n">eps</span><span class="p">):</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">L</span>
        <span class="k">elif</span> <span class="n">Lobj</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">Hobj</span> <span class="o">-</span> <span class="n">eps</span><span class="p">):</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">H</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">alph2</span>

    <span class="c1"># Push a2 to 0 or C if very close</span>
    <span class="k">if</span> <span class="n">a2</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">:</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">elif</span> <span class="n">a2</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">C</span> <span class="o">-</span> <span class="mf">1e-8</span><span class="p">):</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span>

    <span class="c1"># If examples can&#39;t be optimized within epsilon (eps), skip this pair</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a2</span> <span class="o">-</span> <span class="n">alph2</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span> <span class="o">*</span> <span class="p">(</span><span class="n">a2</span> <span class="o">+</span> <span class="n">alph2</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)):</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="n">model</span>

    <span class="c1"># Calculate new alpha 1 (a1)</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">alph1</span> <span class="o">+</span> <span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="n">alph2</span> <span class="o">-</span> <span class="n">a2</span><span class="p">)</span>

    <span class="c1"># Update threshold b to reflect newly calculated alphas</span>
    <span class="c1"># Calculate both possible thresholds</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">E1</span> <span class="o">+</span> <span class="n">y1</span> <span class="o">*</span> <span class="p">(</span><span class="n">a1</span> <span class="o">-</span> <span class="n">alph1</span><span class="p">)</span> <span class="o">*</span> <span class="n">k11</span> <span class="o">+</span> <span class="n">y2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a2</span> <span class="o">-</span> <span class="n">alph2</span><span class="p">)</span> <span class="o">*</span> <span class="n">k12</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">E2</span> <span class="o">+</span> <span class="n">y1</span> <span class="o">*</span> <span class="p">(</span><span class="n">a1</span> <span class="o">-</span> <span class="n">alph1</span><span class="p">)</span> <span class="o">*</span> <span class="n">k12</span> <span class="o">+</span> <span class="n">y2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a2</span> <span class="o">-</span> <span class="n">alph2</span><span class="p">)</span> <span class="o">*</span> <span class="n">k22</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span>

    <span class="c1"># Set new threshold based on if a1 or a2 is bound by L and/or H</span>
    <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">a1</span> <span class="ow">and</span> <span class="n">a1</span> <span class="o">&lt;</span> <span class="n">C</span><span class="p">:</span>
        <span class="n">b_new</span> <span class="o">=</span> <span class="n">b1</span>
    <span class="k">elif</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">a2</span> <span class="ow">and</span> <span class="n">a2</span> <span class="o">&lt;</span> <span class="n">C</span><span class="p">:</span>
        <span class="n">b_new</span> <span class="o">=</span> <span class="n">b2</span>
    <span class="c1"># Average thresholds if both are bound</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">b_new</span> <span class="o">=</span> <span class="p">(</span><span class="n">b1</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>

    <span class="c1"># Update model object with new alphas &amp; threshold</span>
    <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span>
    <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">a2</span>

    <span class="c1"># Update error cache</span>
    <span class="c1"># Error cache for optimized alphas is set to 0 if they&#39;re unbound</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">alph</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="p">[</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">]):</span>
        <span class="k">if</span> <span class="mf">0.0</span> <span class="o">&lt;</span> <span class="n">alph</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Set non-optimized errors based on equation 12.11 in Platt&#39;s book</span>
    <span class="n">non_opt</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="o">!=</span> <span class="n">i1</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">!=</span> <span class="n">i2</span><span class="p">)]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">non_opt</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">non_opt</span><span class="p">]</span> <span class="o">+</span> \
        <span class="n">y1</span><span class="o">*</span><span class="p">(</span><span class="n">a1</span> <span class="o">-</span> <span class="n">alph1</span><span class="p">)</span><span class="o">*</span><span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i1</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">non_opt</span><span class="p">])</span> <span class="o">+</span> \
        <span class="n">y2</span><span class="o">*</span><span class="p">(</span><span class="n">a2</span> <span class="o">-</span> <span class="n">alph2</span><span class="p">)</span> <span class="o">*</span> \
        <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i2</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">non_opt</span><span class="p">])</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span> <span class="o">-</span> <span class="n">b_new</span>

    <span class="c1"># Update model threshold</span>
    <span class="n">model</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b_new</span>

    <span class="k">return</span> <span class="mi">1</span><span class="p">,</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">examine_example</span><span class="p">(</span><span class="n">i2</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

    <span class="n">y2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">alph2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">E2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">E2</span> <span class="o">*</span> <span class="n">y2</span>

    <span class="c1"># Proceed if error is within specified tolerance (tol)</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">r2</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">tol</span> <span class="ow">and</span> <span class="n">alph2</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">r2</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">alph2</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">[(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">)])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Use 2nd choice heuristic is choose max difference in error</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">i1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">[</span><span class="n">i2</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">i1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
            <span class="n">step_result</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">take_step</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step_result</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">1</span><span class="p">,</span> <span class="n">model</span>

        <span class="c1"># Loop through non-zero and non-C alphas, starting at a random point</span>
        <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">))[</span><span class="mi">0</span><span class="p">],</span>
                          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">m</span><span class="p">))):</span>
            <span class="n">step_result</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">take_step</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step_result</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">1</span><span class="p">,</span> <span class="n">model</span>

        <span class="c1"># loop through all alphas, starting at a random point</span>
        <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">m</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">m</span><span class="p">))):</span>
            <span class="n">step_result</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">take_step</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step_result</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">1</span><span class="p">,</span> <span class="n">model</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>

    <span class="n">numChanged</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">examineAll</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># loop over each alpha in first round</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">numChanged</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">examineAll</span><span class="p">):</span>
        <span class="n">numChanged</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">examineAll</span><span class="p">:</span>
            <span class="c1"># loop over all training examples</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">examine_result</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">examine_example</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
                <span class="n">numChanged</span> <span class="o">+=</span> <span class="n">examine_result</span>
                <span class="k">if</span> <span class="n">examine_result</span><span class="p">:</span>
                    <span class="n">obj_result</span> <span class="o">=</span> <span class="n">objective_function</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">_obj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_result</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># loop over examples where alphas are not already at their limits</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">C</span><span class="p">))[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">examine_result</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">examine_example</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
                <span class="n">numChanged</span> <span class="o">+=</span> <span class="n">examine_result</span>
                <span class="k">if</span> <span class="n">examine_result</span><span class="p">:</span>
                    <span class="n">obj_result</span> <span class="o">=</span> <span class="n">objective_function</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">_obj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_result</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">examineAll</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">examineAll</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">numChanged</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">examineAll</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>We are now ready to define the model (after defining some hyperparameters).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set model parameters and initial values</span>
<span class="n">C</span> <span class="o">=</span> <span class="mf">1000.0</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">initial_alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">initial_b</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># Set tolerances</span>
<span class="n">tol</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># error tolerance</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># alpha tolerance</span>

<span class="c1"># Instantiate model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SMOModel</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> 
    <span class="n">kernel</span><span class="o">=</span><span class="n">linear_kernel</span><span class="p">,</span>
    <span class="n">alphas</span><span class="o">=</span><span class="n">initial_alphas</span><span class="p">,</span>
    <span class="n">b</span><span class="o">=</span><span class="n">initial_b</span><span class="p">,</span>
    <span class="n">errors</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Initialize error cache</span>
<span class="n">initial_error</span> <span class="o">=</span> <span class="n">decision_function</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
                                  <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span>
<span class="n">model</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">initial_error</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show initial performance</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">grid</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_37058/1098051293.py:18: UserWarning: No contour levels were found within the data range.
  ax.contour(xrange, yrange, grid, levels=levels, linewidths=(1, 1, 1),
</pre></div>
</div>
<img alt="../_images/4_SVM_20_1.png" src="../_images/4_SVM_20_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">grid</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4_SVM_22_0.png" src="../_images/4_SVM_22_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss curve</span>
<span class="c1"># note: we started with all alphas = 0 and turned some of them on one by one, and then refined.</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_obj</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7fd8accbba30&gt;]
</pre></div>
</div>
<img alt="../_images/4_SVM_23_1.png" src="../_images/4_SVM_23_1.png" />
</div>
</div>
</section>
<section id="gradient-descent-optimization">
<h2>4.3 Gradient Descent Optimization<a class="headerlink" href="#gradient-descent-optimization" title="Permalink to this headline">#</a></h2>
<p>We can also directly solve the primal problem with gradient-based optimization, if we slightly reformulate it. This reformulation requires using the hinge loss <span class="math notranslate nohighlight">\(\max(0, y_{pred}-1)\)</span></p>
<p><strong>Visualization Utils</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_torch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    based on </span>
<span class="sd">    https://scikit-learn.org/stable/auto_examples/svm/plot_svm_margin.html#sphx-glr-auto-examples-svm-plot-svm-margin-py</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">model</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">w</span> <span class="o">==</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">b</span> <span class="o">==</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Either w, b or model can be provided&quot;</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># extend bounds by 0.1 to improve the plot</span>
    <span class="n">x_min</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.1</span>
    <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.1</span>

    <span class="c1"># solving $w0+x1 + w1*x2 + b = 0$ for $x2$ leads to $x2 = -w0/w1 - b/w1$</span>
    <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="n">yy</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">xx</span> <span class="o">-</span> <span class="n">b</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># $margin = 1 / ||w||_2$</span>
    <span class="c1"># Why? Recall that the distance between a point (x_p, y_P) and a line</span>
    <span class="c1"># $ax+by+c=0$ is given by $|ax_p+by_p+c|/\sqrt{a^2+b^2}$. As we set the</span>
    <span class="c1"># functional margin to 1, i.e. $|ax_i+by_i+c|=1$ for a support vector</span>
    <span class="c1"># point, then the total margin becomes $1 / ||w||_2$.</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">yy_up</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>
    <span class="n">yy_down</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="s2">&quot;k-&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_up</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_down</span><span class="p">,</span> <span class="s2">&quot;b--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s first look at the case of a linear kernel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SupportVectorMachine</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Some preparation before we train the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prepare the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set hyperparameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># initialize model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SupportVectorMachine</span><span class="p">()</span>
<span class="c1"># define hinge loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">out</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># print initial parameters</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;: &quot;</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model.weight :  tensor([[-0.0933, -0.4716]])
model.bias :  tensor([-0.3917])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize decision boundary and margins before training</span>
<span class="n">visualize_torch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4_SVM_32_0.png" src="../_images/4_SVM_32_0.png" />
</div>
</div>
<p>Now, we train the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">random_nums</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

    <span class="c1"># Iterate over the individual batches</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">random_nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">random_nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epoch </span><span class="si">{}</span><span class="s1">, loss </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch 0, loss 1.0
epoch 1, loss 1.037710428237915
epoch 2, loss 0.6296830177307129
epoch 3, loss 1.0113270282745361
epoch 4, loss 0.9945489764213562
epoch 5, loss 0.9861934185028076
epoch 6, loss 0.9714006185531616
epoch 7, loss 0.9780317544937134
epoch 8, loss 0.9693995118141174
epoch 9, loss 0.8684085011482239
epoch 10, loss 1.0023398399353027
epoch 11, loss 1.01217782497406
epoch 12, loss 0.949317991733551
epoch 13, loss 0.9097648859024048
epoch 14, loss 1.0
epoch 15, loss 1.0052322149276733
epoch 16, loss 0.998340368270874
epoch 17, loss 0.9999999403953552
epoch 18, loss 0.9599748253822327
epoch 19, loss 1.0006119012832642
epoch 20, loss 1.0211067199707031
epoch 21, loss 0.9878845810890198
epoch 22, loss 1.0
epoch 23, loss 0.9629693627357483
epoch 24, loss 0.897744357585907
epoch 25, loss 0.9095276594161987
epoch 26, loss 0.9665170311927795
epoch 27, loss 1.0085572004318237
epoch 28, loss 0.9593522548675537
epoch 29, loss 0.986879289150238
epoch 30, loss 1.0107148885726929
epoch 31, loss 1.0
epoch 32, loss 1.0185199975967407
epoch 33, loss 0.9756385684013367
epoch 34, loss 1.0026373863220215
epoch 35, loss 1.0018682479858398
epoch 36, loss 0.9247942566871643
epoch 37, loss 0.9876608848571777
epoch 38, loss 1.0066548585891724
epoch 39, loss 1.0158905982971191
epoch 40, loss 0.975191593170166
epoch 41, loss 1.0
epoch 42, loss 0.8577518463134766
epoch 43, loss 0.7346863746643066
epoch 44, loss 0.9791869521141052
epoch 45, loss 1.0081143379211426
epoch 46, loss 1.0119354724884033
epoch 47, loss 0.9935455322265625
epoch 48, loss 0.9511392116546631
epoch 49, loss 0.8916271924972534
epoch 50, loss 0.9949738383293152
epoch 51, loss 0.9579364061355591
epoch 52, loss 0.9443272352218628
epoch 53, loss 0.7384126782417297
epoch 54, loss 0.9512062668800354
epoch 55, loss 0.7629111409187317
epoch 56, loss 0.9912386536598206
epoch 57, loss 0.9688662886619568
epoch 58, loss 0.8397905230522156
epoch 59, loss 0.8345715999603271
epoch 60, loss 1.0245447158813477
epoch 61, loss 0.9339427351951599
epoch 62, loss 0.9687446355819702
epoch 63, loss 1.0077906847000122
epoch 64, loss 0.9800364971160889
epoch 65, loss 1.002061128616333
epoch 66, loss 0.8873255848884583
epoch 67, loss 1.0092377662658691
epoch 68, loss 0.9837936162948608
epoch 69, loss 0.9893543124198914
epoch 70, loss 0.8706488609313965
epoch 71, loss 0.7362289428710938
epoch 72, loss 1.0141046047210693
epoch 73, loss 1.019364595413208
epoch 74, loss 0.7662438750267029
epoch 75, loss 0.7309564352035522
epoch 76, loss 0.9788610935211182
epoch 77, loss 0.9100192189216614
epoch 78, loss 1.0000429153442383
epoch 79, loss 0.9911007881164551
epoch 80, loss 0.9126284718513489
epoch 81, loss 0.9845589995384216
epoch 82, loss 0.7803347110748291
epoch 83, loss 1.003717303276062
epoch 84, loss 0.984480082988739
epoch 85, loss 0.8967791199684143
epoch 86, loss 0.9765903353691101
epoch 87, loss 0.9878063797950745
epoch 88, loss 0.8273986577987671
epoch 89, loss 1.0110886096954346
epoch 90, loss 0.9706304669380188
epoch 91, loss 0.9066428542137146
epoch 92, loss 0.9954428672790527
epoch 93, loss 0.8234254717826843
epoch 94, loss 0.9877461194992065
epoch 95, loss 0.8528421521186829
epoch 96, loss 0.9616749286651611
epoch 97, loss 0.9505128264427185
epoch 98, loss 0.9611236453056335
epoch 99, loss 0.8801714181900024
epoch 100, loss 0.9667996168136597
epoch 101, loss 0.9728180766105652
epoch 102, loss 0.9643974304199219
epoch 103, loss 0.7903271317481995
epoch 104, loss 0.8889490365982056
epoch 105, loss 0.9832819104194641
epoch 106, loss 0.9687583446502686
epoch 107, loss 0.9910491704940796
epoch 108, loss 0.7804783582687378
epoch 109, loss 1.003686785697937
epoch 110, loss 0.9917494058609009
epoch 111, loss 0.9186831116676331
epoch 112, loss 1.0098146200180054
epoch 113, loss 0.9875274896621704
epoch 114, loss 0.956317126750946
epoch 115, loss 0.9790907502174377
epoch 116, loss 0.7961788773536682
epoch 117, loss 0.8917703032493591
epoch 118, loss 0.9744589328765869
epoch 119, loss 0.970123291015625
epoch 120, loss 0.9801238775253296
epoch 121, loss 1.0006357431411743
epoch 122, loss 0.9792355298995972
epoch 123, loss 1.012761116027832
epoch 124, loss 0.8514796495437622
epoch 125, loss 0.9091484546661377
epoch 126, loss 0.973507821559906
epoch 127, loss 0.9710741639137268
epoch 128, loss 0.871924638748169
epoch 129, loss 0.970205545425415
epoch 130, loss 1.0
epoch 131, loss 0.963347852230072
epoch 132, loss 0.9796186685562134
epoch 133, loss 0.9902626872062683
epoch 134, loss 0.9236887097358704
epoch 135, loss 1.0043938159942627
epoch 136, loss 1.0
epoch 137, loss 0.9073061943054199
epoch 138, loss 0.9877458810806274
epoch 139, loss 0.9816917181015015
epoch 140, loss 0.8138841390609741
epoch 141, loss 1.002414345741272
epoch 142, loss 0.9521365165710449
epoch 143, loss 0.9593631029129028
epoch 144, loss 1.0
epoch 145, loss 0.9716899991035461
epoch 146, loss 1.0087952613830566
epoch 147, loss 1.0021259784698486
epoch 148, loss 0.5194268226623535
epoch 149, loss 0.9762963652610779
epoch 150, loss 0.9839429259300232
epoch 151, loss 0.9763769507408142
epoch 152, loss 0.8637781739234924
epoch 153, loss 0.9669919013977051
epoch 154, loss 0.9590266942977905
epoch 155, loss 1.007880687713623
epoch 156, loss 0.9882107377052307
epoch 157, loss 0.5884894728660583
epoch 158, loss 0.9663892388343811
epoch 159, loss 0.7169971466064453
epoch 160, loss 0.9799883961677551
epoch 161, loss 1.0017037391662598
epoch 162, loss 1.0
epoch 163, loss 0.788357138633728
epoch 164, loss 0.986650824546814
epoch 165, loss 0.970573902130127
epoch 166, loss 0.9826675653457642
epoch 167, loss 0.8934544324874878
epoch 168, loss 0.8904402852058411
epoch 169, loss 0.9762740135192871
epoch 170, loss 0.997861921787262
epoch 171, loss 0.8700777292251587
epoch 172, loss 0.9037505984306335
epoch 173, loss 0.8753330111503601
epoch 174, loss 0.9642042517662048
epoch 175, loss 0.8835246562957764
epoch 176, loss 0.9822958111763
epoch 177, loss 1.0009410381317139
epoch 178, loss 0.5121200680732727
epoch 179, loss 0.9545382857322693
epoch 180, loss 0.7563140988349915
epoch 181, loss 0.7586513757705688
epoch 182, loss 0.9632856845855713
epoch 183, loss 1.0
epoch 184, loss 1.0048812627792358
epoch 185, loss 1.002465009689331
epoch 186, loss 0.8616963028907776
epoch 187, loss 1.0095605850219727
epoch 188, loss 1.0203423500061035
epoch 189, loss 1.0025535821914673
epoch 190, loss 0.9824723601341248
epoch 191, loss 0.5613083839416504
epoch 192, loss 0.983604907989502
epoch 193, loss 1.0
epoch 194, loss 0.9760587811470032
epoch 195, loss 1.0082528591156006
epoch 196, loss 0.9061172008514404
epoch 197, loss 0.9452160000801086
epoch 198, loss 0.8762983679771423
epoch 199, loss 0.7515954375267029
epoch 200, loss 0.5494152307510376
epoch 201, loss 1.0186548233032227
epoch 202, loss 1.0054141283035278
epoch 203, loss 0.7501610517501831
epoch 204, loss 1.0
epoch 205, loss 0.9583802819252014
epoch 206, loss 1.0
epoch 207, loss 1.0093626976013184
epoch 208, loss 0.9903441071510315
epoch 209, loss 1.0031989812850952
epoch 210, loss 1.0
epoch 211, loss 1.001011848449707
epoch 212, loss 0.9290847778320312
epoch 213, loss 1.0122004747390747
epoch 214, loss 0.8874508738517761
epoch 215, loss 0.7990261316299438
epoch 216, loss 1.0071334838867188
epoch 217, loss 0.6306087374687195
epoch 218, loss 0.8529619574546814
epoch 219, loss 0.8529518842697144
epoch 220, loss 0.7092634439468384
epoch 221, loss 0.981809675693512
epoch 222, loss 1.002475619316101
epoch 223, loss 0.47598302364349365
epoch 224, loss 1.0082573890686035
epoch 225, loss 1.0048518180847168
epoch 226, loss 0.9657196998596191
epoch 227, loss 0.9756826162338257
epoch 228, loss 0.992584228515625
epoch 229, loss 1.0189528465270996
epoch 230, loss 1.0000001192092896
epoch 231, loss 1.0026452541351318
epoch 232, loss 1.0
epoch 233, loss 0.9184619188308716
epoch 234, loss 0.8553222417831421
epoch 235, loss 0.9880959391593933
epoch 236, loss 0.9933522939682007
epoch 237, loss 0.9283249378204346
epoch 238, loss 1.0179874897003174
epoch 239, loss 0.9636187553405762
epoch 240, loss 0.9878755807876587
epoch 241, loss 0.9719681739807129
epoch 242, loss 0.9595047235488892
epoch 243, loss 0.9910354018211365
epoch 244, loss 0.9570895433425903
epoch 245, loss 0.9591806530952454
epoch 246, loss 1.0000388622283936
epoch 247, loss 0.965547502040863
epoch 248, loss 0.9517300128936768
epoch 249, loss 0.8599995970726013
epoch 250, loss 0.9136371612548828
epoch 251, loss 0.8980486392974854
epoch 252, loss 0.9786529541015625
epoch 253, loss 0.9497442841529846
epoch 254, loss 0.9951822757720947
epoch 255, loss 1.0067527294158936
epoch 256, loss 1.0000001192092896
epoch 257, loss 0.8979646563529968
epoch 258, loss 1.004197359085083
epoch 259, loss 0.9647287130355835
epoch 260, loss 1.0029557943344116
epoch 261, loss 0.9807553887367249
epoch 262, loss 1.005663275718689
epoch 263, loss 0.8616124987602234
epoch 264, loss 0.8937824964523315
epoch 265, loss 0.8443956971168518
epoch 266, loss 0.958560049533844
epoch 267, loss 0.8879004120826721
epoch 268, loss 0.9644744992256165
epoch 269, loss 0.8711795210838318
epoch 270, loss 0.9884974956512451
epoch 271, loss 0.9712914228439331
epoch 272, loss 0.8592371344566345
epoch 273, loss 0.9797601103782654
epoch 274, loss 1.0098210573196411
epoch 275, loss 1.0173571109771729
epoch 276, loss 0.9753369092941284
epoch 277, loss 0.9819003343582153
epoch 278, loss 0.980548083782196
epoch 279, loss 0.9698505401611328
epoch 280, loss 0.8970954418182373
epoch 281, loss 0.9907931685447693
epoch 282, loss 1.0
epoch 283, loss 0.8580665588378906
epoch 284, loss 1.0051864385604858
epoch 285, loss 1.002549171447754
epoch 286, loss 0.9906319379806519
epoch 287, loss 1.0066957473754883
epoch 288, loss 0.9851635098457336
epoch 289, loss 1.0000001192092896
epoch 290, loss 0.9379422068595886
epoch 291, loss 0.9875370264053345
epoch 292, loss 0.7273862957954407
epoch 293, loss 0.7680506110191345
epoch 294, loss 0.7416651248931885
epoch 295, loss 1.0
epoch 296, loss 0.9598860740661621
epoch 297, loss 0.9698327779769897
epoch 298, loss 0.9593179225921631
epoch 299, loss 1.0000001192092896
epoch 300, loss 0.8532005548477173
epoch 301, loss 0.9585923552513123
epoch 302, loss 0.9498233199119568
epoch 303, loss 0.9403447508811951
epoch 304, loss 0.906289279460907
epoch 305, loss 0.9654911756515503
epoch 306, loss 1.0098098516464233
epoch 307, loss 1.0045851469039917
epoch 308, loss 0.9055326581001282
epoch 309, loss 0.9596560001373291
epoch 310, loss 0.9923341274261475
epoch 311, loss 0.9579740166664124
epoch 312, loss 1.0055687427520752
epoch 313, loss 0.9852626323699951
epoch 314, loss 0.9931254386901855
epoch 315, loss 0.8835042715072632
epoch 316, loss 0.9773779511451721
epoch 317, loss 0.9894806742668152
epoch 318, loss 0.9837033748626709
epoch 319, loss 0.9554867744445801
epoch 320, loss 0.9760284423828125
epoch 321, loss 0.893510639667511
epoch 322, loss 0.8810583353042603
epoch 323, loss 0.9006463885307312
epoch 324, loss 0.9811911582946777
epoch 325, loss 0.9806697368621826
epoch 326, loss 0.9800317883491516
epoch 327, loss 0.9075248837471008
epoch 328, loss 1.0008519887924194
epoch 329, loss 0.9168627858161926
epoch 330, loss 0.9574272632598877
epoch 331, loss 0.9561792016029358
epoch 332, loss 0.7682241201400757
epoch 333, loss 0.9875774383544922
epoch 334, loss 1.0104649066925049
epoch 335, loss 1.0000001192092896
epoch 336, loss 0.7380847334861755
epoch 337, loss 0.892010509967804
epoch 338, loss 0.9773390889167786
epoch 339, loss 0.7902604937553406
epoch 340, loss 0.4683600664138794
epoch 341, loss 0.978522539138794
epoch 342, loss 0.8834629654884338
epoch 343, loss 0.9599162340164185
epoch 344, loss 0.4535447061061859
epoch 345, loss 0.9020493030548096
epoch 346, loss 0.8817819952964783
epoch 347, loss 0.7557035684585571
epoch 348, loss 0.7607058882713318
epoch 349, loss 1.0024312734603882
epoch 350, loss 1.0117783546447754
epoch 351, loss 0.8831143379211426
epoch 352, loss 1.003628134727478
epoch 353, loss 0.9970279932022095
epoch 354, loss 0.9928879737854004
epoch 355, loss 1.0021123886108398
epoch 356, loss 0.9692739844322205
epoch 357, loss 0.9714933633804321
epoch 358, loss 0.8298184871673584
epoch 359, loss 0.9778311252593994
epoch 360, loss 0.9999999403953552
epoch 361, loss 1.0091196298599243
epoch 362, loss 0.9698331356048584
epoch 363, loss 1.0002210140228271
epoch 364, loss 0.9810900688171387
epoch 365, loss 0.895753026008606
epoch 366, loss 0.9999999403953552
epoch 367, loss 0.9808343648910522
epoch 368, loss 0.9095247387886047
epoch 369, loss 0.9051044583320618
epoch 370, loss 0.9603816270828247
epoch 371, loss 0.8914593458175659
epoch 372, loss 0.7400664687156677
epoch 373, loss 1.01244056224823
epoch 374, loss 1.005530595779419
epoch 375, loss 0.8937408924102783
epoch 376, loss 0.9999999403953552
epoch 377, loss 0.9905313849449158
epoch 378, loss 0.9680088758468628
epoch 379, loss 1.012833833694458
epoch 380, loss 0.9222905039787292
epoch 381, loss 0.8726086616516113
epoch 382, loss 0.9703901410102844
epoch 383, loss 0.8023843169212341
epoch 384, loss 0.9846141934394836
epoch 385, loss 0.9850583076477051
epoch 386, loss 1.002663254737854
epoch 387, loss 0.9758524298667908
epoch 388, loss 0.9828431606292725
epoch 389, loss 1.0092377662658691
epoch 390, loss 0.9665771722793579
epoch 391, loss 0.971088707447052
epoch 392, loss 0.7102927565574646
epoch 393, loss 1.0117775201797485
epoch 394, loss 0.8697155117988586
epoch 395, loss 0.9765112996101379
epoch 396, loss 0.9902604818344116
epoch 397, loss 1.0086578130722046
epoch 398, loss 1.0054203271865845
epoch 399, loss 0.9786081910133362
epoch 400, loss 0.8920361995697021
epoch 401, loss 0.9866202473640442
epoch 402, loss 0.9770287871360779
epoch 403, loss 0.9890164732933044
epoch 404, loss 1.0045239925384521
epoch 405, loss 0.9881640672683716
epoch 406, loss 1.0
epoch 407, loss 1.0
epoch 408, loss 0.8671116828918457
epoch 409, loss 0.891978919506073
epoch 410, loss 1.020151138305664
epoch 411, loss 1.0041978359222412
epoch 412, loss 0.9294971227645874
epoch 413, loss 1.0149617195129395
epoch 414, loss 1.0264673233032227
epoch 415, loss 0.9866558909416199
epoch 416, loss 1.0095648765563965
epoch 417, loss 0.9810484051704407
epoch 418, loss 0.9627165794372559
epoch 419, loss 0.9719622731208801
epoch 420, loss 0.9663816094398499
epoch 421, loss 0.9863829016685486
epoch 422, loss 0.7488980293273926
epoch 423, loss 1.0120466947555542
epoch 424, loss 0.9063392877578735
epoch 425, loss 0.9891396164894104
epoch 426, loss 0.959923505783081
epoch 427, loss 1.0116605758666992
epoch 428, loss 0.9766094088554382
epoch 429, loss 0.9782812595367432
epoch 430, loss 0.8980039358139038
epoch 431, loss 1.0141191482543945
epoch 432, loss 0.8946372270584106
epoch 433, loss 0.993833601474762
epoch 434, loss 0.9823238253593445
epoch 435, loss 1.008481502532959
epoch 436, loss 0.9835047125816345
epoch 437, loss 1.004319429397583
epoch 438, loss 1.0035380125045776
epoch 439, loss 0.5526009202003479
epoch 440, loss 1.0
epoch 441, loss 0.9544010162353516
epoch 442, loss 0.9606465101242065
epoch 443, loss 0.703154981136322
epoch 444, loss 1.0013070106506348
epoch 445, loss 0.9989950656890869
epoch 446, loss 0.9454715251922607
epoch 447, loss 0.9741108417510986
epoch 448, loss 0.9434594511985779
epoch 449, loss 1.0
epoch 450, loss 1.0007059574127197
epoch 451, loss 1.0176995992660522
epoch 452, loss 1.0
epoch 453, loss 0.9707262516021729
epoch 454, loss 0.9805618524551392
epoch 455, loss 1.0
epoch 456, loss 0.7681581377983093
epoch 457, loss 0.982069194316864
epoch 458, loss 1.0030490159988403
epoch 459, loss 0.8722622394561768
epoch 460, loss 0.876607358455658
epoch 461, loss 1.0
epoch 462, loss 0.9416155219078064
epoch 463, loss 1.0
epoch 464, loss 0.9782851934432983
epoch 465, loss 0.9732925891876221
epoch 466, loss 0.977173388004303
epoch 467, loss 1.0069071054458618
epoch 468, loss 0.9822711944580078
epoch 469, loss 0.9624573588371277
epoch 470, loss 0.8626136183738708
epoch 471, loss 0.978076159954071
epoch 472, loss 1.0003551244735718
epoch 473, loss 0.9664459228515625
epoch 474, loss 0.9116548299789429
epoch 475, loss 0.9754084944725037
epoch 476, loss 0.862754762172699
epoch 477, loss 0.9111805558204651
epoch 478, loss 1.0055004358291626
epoch 479, loss 0.9605598449707031
epoch 480, loss 1.0030605792999268
epoch 481, loss 0.960761308670044
epoch 482, loss 0.9067330360412598
epoch 483, loss 1.000022530555725
epoch 484, loss 0.5202656388282776
epoch 485, loss 1.0
epoch 486, loss 0.9726881980895996
epoch 487, loss 0.9858840107917786
epoch 488, loss 0.9793750643730164
epoch 489, loss 1.0
epoch 490, loss 1.005529522895813
epoch 491, loss 0.9803292751312256
epoch 492, loss 1.0030367374420166
epoch 493, loss 1.0
epoch 494, loss 0.9892929792404175
epoch 495, loss 0.9686628580093384
epoch 496, loss 0.9758394360542297
epoch 497, loss 1.0088305473327637
epoch 498, loss 0.9633033871650696
epoch 499, loss 0.990884006023407
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print final parameters</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;: &quot;</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model.weight :  tensor([[ 0.0682, -0.7003]])
model.bias :  tensor([0.0114])
</pre></div>
</div>
</div>
</div>
<p>In this formulation all samples are used to fit the parameters. This in contranst to the SMO solution might take longer to optimize, but is more stable because we don’t select individial samples and ignore all the others.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_torch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4_SVM_37_0.png" src="../_images/4_SVM_37_0.png" />
</div>
</div>
<p><strong>Exercise</strong></p>
<p>Implement the Radial Basis Function (RBF) kernel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###########</span>
<span class="c1"># TODO: </span>


<span class="c1">###########</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./exercise"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="3_optimization.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3. Optimization</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../admin.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Admin</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By N. Adams, L. Paehler, A. Toshev<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>